{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             text    label\n",
      "0                Saya sangat menyukai produk ini!  positif\n",
      "1  Ini adalah hal terburuk yang pernah saya beli.  negatif\n",
      "2       Saya sangat senang dengan pembelian saya.  positif\n",
      "3                          Saya benci barang ini.  negatif\n",
      "4                                 Ini luar biasa!  positif\n",
      "5                Saya tidak suka ini sama sekali.  negatif\n",
      "6              Pengalaman yang sangat luar biasa.  positif\n",
      "7      Tidak sesuai harapan, sangat mengecewakan.  negatif\n",
      "8     Kualitas produk sangat bagus dan saya puas!  positif\n",
      "9       Barang ini sangat buruk dan mengecewakan.  negatif\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Buat dataset sederhana\n",
    "data = {\n",
    "    'text': [\n",
    "        'Saya sangat menyukai produk ini!', \n",
    "        'Ini adalah hal terburuk yang pernah saya beli.', \n",
    "        'Saya sangat senang dengan pembelian saya.', \n",
    "        'Saya benci barang ini.', \n",
    "        'Ini luar biasa!', \n",
    "        'Saya tidak suka ini sama sekali.', \n",
    "        'Pengalaman yang sangat luar biasa.', \n",
    "        'Tidak sesuai harapan, sangat mengecewakan.',\n",
    "        'Kualitas produk sangat bagus dan saya puas!',\n",
    "        'Barang ini sangat buruk dan mengecewakan.'\n",
    "    ],\n",
    "    'label': ['positif', 'negatif', 'positif', 'negatif', 'positif', 'negatif', 'positif', 'negatif', 'positif', 'negatif']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopword: Package 'stopword' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#terapkan preprocessing\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_text)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "import string \n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopword') # instalasi stemmer sastrawi\n",
    "\n",
    "def preprocess_teks(text):\n",
    "    text = text.lower() #mengubah teks ke huruf kecil\n",
    "    text = text.translate(str.makestrans('', '', string.punctuation)) #menghapus tanda baca\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split()) # stemming\n",
    "    stop_words = set(stopwords.words('indonesian')) #enghapus stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "#terapkan preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(df[['text', 'cleaned_text']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
